# -*- coding: utf-8 -*-
"""Plant Disease Detection(23cs067).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YaZ-m95DFUCcjKMKdpK0pVCKWr7GcUBm
"""

import kagglehub

# Download latest version of the PlantVillage dataset
path = kagglehub.dataset_download("moazeldsokyx/plantvillage")

print("âœ… Dataset downloaded successfully!")
print("ðŸ“‚ Path to dataset files:", path)

import os

base_dir = "/kaggle/input/plantvillage/dataset"

train_dir = os.path.join(base_dir, "train")
test_dir = os.path.join(base_dir, "test")

print("ðŸ“‚ Train dir:", train_dir)
print("ðŸ“‚ Test dir:", test_dir)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

img_size = (128, 128)
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical'
)

test_gen = test_datagen.flow_from_directory(
    test_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

# ================================
# 1. Setup & Imports
# ================================
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, Sequential
from tensorflow.keras.layers import Dense
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from PIL import Image

# ================================
# 2. Dataset Paths
# ================================
base_dir = "/kaggle/input/plantvillage/dataset"
train_dir = os.path.join(base_dir, "train")
test_dir = os.path.join(base_dir, "test")

print("ðŸ“‚ Train dir:", train_dir)
print("ðŸ“‚ Test dir:", test_dir)

# ================================
# 3. Data Generators (for CNN)
# ================================
img_size = (128, 128)
batch_size = 32

train_datagen = ImageDataGenerator(rescale=1./255)
test_datagen = ImageDataGenerator(rescale=1./255)

train_gen = train_datagen.flow_from_directory(
    train_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical'
)

test_gen = test_datagen.flow_from_directory(
    test_dir, target_size=img_size, batch_size=batch_size,
    class_mode='categorical', shuffle=False
)

# ================================
# 4. CNN Model
# ================================
cnn = models.Sequential([
    layers.Input(shape=(128,128,3)),
    layers.Conv2D(32, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(64, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Conv2D(128, (3,3), activation='relu'),
    layers.MaxPooling2D(2,2),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(train_gen.num_classes, activation='softmax')
])

cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cnn.summary()

# Train CNN
history_cnn = cnn.fit(train_gen, validation_data=test_gen, epochs=5)

# ================================
# 5. CNN Evaluation
# ================================
y_pred_cnn = cnn.predict(test_gen)
y_pred_cnn_classes = y_pred_cnn.argmax(axis=1)
y_true_cnn = test_gen.classes

print("ðŸ“Š CNN Classification Report:")
print(classification_report(y_true_cnn, y_pred_cnn_classes, target_names=list(test_gen.class_indices.keys())))

# ================================
# 6. Feature Extraction for Tabular NN
# ================================
def extract_features(img_path):
    img = Image.open(img_path).resize((128,128))
    img_arr = np.array(img)

    # RGB mean & std
    features = []
    for i in range(3):  # R, G, B
        channel = img_arr[:,:,i]
        features.append(channel.mean())
        features.append(channel.std())

    # Grayscale histogram (16 bins)
    gray = img.convert("L")
    hist = np.histogram(np.array(gray), bins=16, range=(0,256))[0]
    hist = hist / hist.sum()
    features.extend(hist)

    return features

X, y = [], []
class_labels = os.listdir(train_dir)

for label_idx, label in enumerate(class_labels):
    class_folder = os.path.join(train_dir, label)
    for img_name in os.listdir(class_folder)[:200]:  # limit to speed up
        img_path = os.path.join(class_folder, img_name)
        try:
            feats = extract_features(img_path)
            X.append(feats)
            y.append(label_idx)
        except:
            continue

X = np.array(X)
y = np.array(y)

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ================================
# 7. Tabular NN
# ================================
tab_nn = Sequential([
    Dense(64, activation="relu", input_shape=(X_train.shape[1],)),
    Dense(32, activation="relu"),
    Dense(len(class_labels), activation="softmax")
])

tab_nn.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
tab_nn.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)

# Evaluate
y_pred_tab = tab_nn.predict(X_test).argmax(axis=1)

print("ðŸ“Š Tabular NN Classification Report:")
print(classification_report(y_test, y_pred_tab, target_names=class_labels))

tab_nn = Sequential([
    Dense(64, activation="relu", input_shape=(X_train.shape[1],)),
    Dense(32, activation="relu"),
    Dense(len(class_labels), activation="softmax")
])
from tensorflow.keras.layers import Dropout

tab_nn = Sequential([
    Dense(256, activation="relu", input_shape=(X_train.shape[1],)),
    Dropout(0.3),
    Dense(128, activation="relu"),
    Dropout(0.3),
    Dense(64, activation="relu"),
    Dense(len(class_labels), activation="softmax")
])

tab_nn.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

history_tab = tab_nn.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=30,  # more epochs
    batch_size=32,
    verbose=1
)

# Evaluate
y_pred_tab = tab_nn.predict(X_test).argmax(axis=1)

print("ðŸ“Š Improved Tabular NN Classification Report:")
print(classification_report(y_test, y_pred_tab, target_names=class_labels))

from scipy.stats import skew, kurtosis

def extract_features(img_path):
    img = Image.open(img_path).resize((128,128))
    img_arr = np.array(img)

    features = []

    # --- RGB statistics ---
    for i in range(3):  # R, G, B
        channel = img_arr[:,:,i].flatten()
        features.append(channel.mean())
        features.append(channel.std())
        features.append(np.var(channel))
        features.append(skew(channel))
        features.append(kurtosis(channel))

        # RGB histogram (16 bins)
        hist = np.histogram(channel, bins=16, range=(0,256))[0]
        hist = hist / hist.sum()
        features.extend(hist)

    # --- Grayscale histogram (32 bins) ---
    gray = img.convert("L")
    hist_gray = np.histogram(np.array(gray), bins=32, range=(0,256))[0]
    hist_gray = hist_gray / hist_gray.sum()
    features.extend(hist_gray)

    return features

from tensorflow.keras.layers import Dropout

tab_nn = Sequential([
    Dense(512, activation="relu", input_shape=(X_train.shape[1],)),
    Dropout(0.4),
    Dense(256, activation="relu"),
    Dropout(0.3),
    Dense(128, activation="relu"),
    Dense(len(class_labels), activation="softmax")
])

tab_nn.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

history_tab = tab_nn.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=50,   # train longer
    batch_size=64,
    verbose=1
)

y_pred_tab = tab_nn.predict(X_test).argmax(axis=1)

print("ðŸ“Š Tabular NN Report:")
print(classification_report(y_test, y_pred_tab, target_names=class_labels))

import pandas as pd
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score

# --- CNN evaluation ---
y_pred_cnn = cnn.predict(test_gen).argmax(axis=1)
y_true_cnn = test_gen.classes

cnn_acc = accuracy_score(y_true_cnn, y_pred_cnn)
cnn_prec = precision_score(y_true_cnn, y_pred_cnn, average="weighted")
cnn_rec = recall_score(y_true_cnn, y_pred_cnn, average="weighted")
cnn_f1 = f1_score(y_true_cnn, y_pred_cnn, average="weighted")

# --- Tabular NN evaluation ---
y_pred_tab = tab_nn.predict(X_test).argmax(axis=1)

tab_acc = accuracy_score(y_test, y_pred_tab)
tab_prec = precision_score(y_test, y_pred_tab, average="weighted")
tab_rec = recall_score(y_test, y_pred_tab, average="weighted")
tab_f1 = f1_score(y_test, y_pred_tab, average="weighted")

# --- Build result table ---
results = pd.DataFrame({
    "Model": ["CNN", "Tabular NN"],
    "Accuracy": [cnn_acc, tab_acc],
    "Precision": [cnn_prec, tab_prec],
    "Recall": [cnn_rec, tab_rec],
    "F1-score": [cnn_f1, tab_f1]
})

print("ðŸ“Š Model Performance Comparison")
print(results)

import matplotlib.pyplot as plt

# Metrics
metrics = ["Accuracy", "Precision", "Recall", "F1-score"]
cnn_scores = [cnn_acc, cnn_prec, cnn_rec, cnn_f1]
tab_scores = [tab_acc, tab_prec, tab_rec, tab_f1]

x = np.arange(len(metrics))  # positions
width = 0.35  # bar width

plt.figure(figsize=(8,6))
plt.bar(x - width/2, cnn_scores, width, label="CNN")
plt.bar(x + width/2, tab_scores, width, label="Tabular NN")

# Labels & formatting
plt.xticks(x, metrics)
plt.ylabel("Score")
plt.ylim(0, 1)
plt.title("ðŸ“Š CNN vs Tabular NN Performance Comparison")
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Data
results = {
    "CNN": [cnn_acc, cnn_prec, cnn_rec, cnn_f1],
    "Tabular NN": [tab_acc, tab_prec, tab_rec, tab_f1]
}

metrics = ["Accuracy", "Precision", "Recall", "F1-score"]

# Convert to array
data = np.array(list(results.values()))

# Plot heatmap
plt.figure(figsize=(8,5))
plt.imshow(data, cmap="viridis", aspect="auto")

# Show values on heatmap
for i in range(data.shape[0]):
    for j in range(data.shape[1]):
        plt.text(j, i, f"{data[i, j]:.2f}", ha="center", va="center", color="white")

# Labels
plt.xticks(np.arange(len(metrics)), metrics)
plt.yticks(np.arange(len(results)), list(results.keys()))
plt.colorbar(label="Score")
plt.title("Model Performance Heatmap")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Metrics
metrics = ["Accuracy", "Precision", "Recall", "F1-score"]
cnn_scores = [cnn_acc, cnn_prec, cnn_rec, cnn_f1]
tab_scores = [tab_acc, tab_prec, tab_rec, tab_f1]

x = np.arange(len(metrics))  # X positions

plt.figure(figsize=(9,6))

# CNN line
plt.plot(x, cnn_scores, marker='o', label="CNN", linewidth=2)

# Tabular NN line
plt.plot(x, tab_scores, marker='s', label="Tabular NN", linewidth=2)

# Difference line (CNN - Tabular NN)
diff_scores = np.array(cnn_scores) - np.array(tab_scores)
plt.plot(x, diff_scores, marker='^', linestyle="--", label="Difference (CNN - NN)", linewidth=2)

# Annotate values
for i, val in enumerate(cnn_scores):
    plt.text(x[i], val+0.02, f"{val:.2f}", ha="center", color="blue")
for i, val in enumerate(tab_scores):
    plt.text(x[i], val-0.05, f"{val:.2f}", ha="center", color="orange")
for i, val in enumerate(diff_scores):
    plt.text(x[i], val-0.08, f"Î”{val:.2f}", ha="center", color="green")

# Labels & formatting
plt.xticks(x, metrics)
plt.ylabel("Score")
plt.ylim(0, 1.1)
plt.title("ðŸ“ˆ CNN vs Tabular NN Performance + Difference")
plt.legend()
plt.grid(True)
plt.show()

